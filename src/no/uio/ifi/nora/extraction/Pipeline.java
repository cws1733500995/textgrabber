package no.uio.ifi.nora.extraction;

import java.io.BufferedInputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.InputStream;
import java.net.URL;
import java.util.LinkedList;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;

import org.apache.pdfbox.cos.COSName;

import org.apache.pdfbox.pdmodel.font.PDFont;
import org.jdom.Document;
import org.jdom.output.Format;

/**
 * Represents our pipeline. The Extractor is first called to extract from  the given PDF, either with a File instance, or an URL.
 * Then using ie, process() all PipelineElement in elements will be called to work on the XML in order of apperance.
 * @author johanbev
 *
 */
public class Pipeline 
{
	private TextGrabber extractor;
	private LinkedList<PipelineElement> elements;
	
	/**
	 * We need to tell PDFont to go fuck-off with its shit into the GC every now and then.
	 * Now we dont have around accesors or anything fancy like that in Java, 
	 * run checkPDFont() for every document pushed through this pipeline,
	 * or spend the rest of your life debugging OutOfMemory exceptions.
	 */
	static protected int numExtracted = 0; //This is static  the PDFont map is.
	static final protected int releaseThreshhold = 5;
	static protected void checkPDFont()
	{
		numExtracted++;
		if(numExtracted > releaseThreshhold)
		{
			numExtracted = 0;
			PDFont.clearResources(); // FFFFFFUUUUUUU
            COSName.clearResources();
		}
	}

	/**
	 * Constructs a Pipeline with the given extractor and elements
	 * @param extractor Extraction object for parsing the PDF
	 * @param elements List of pipeline elements to wash the text with
	 */
	public Pipeline(TextGrabber extractor, LinkedList<PipelineElement> elements) {
		super();
		this.extractor = extractor;
		this.elements = elements;
	}

	/**
	 * Does a complete process (extraction + washing) on the given file
	 * @param f The file to be processed
	 * @return JDOM XML-Document 
	 */
	protected Document process(File f) throws Exception
	{
		InputStream fis = new BufferedInputStream(new FileInputStream(f));
		Document current;
		
		try {
			current = extractor.getDocument(fis, f, true);

			if (elements != null)
				for(PipelineElement pe : elements)
				{
					current = pe.process(current);
				}

		}
		finally
		{
			checkPDFont();
			fis.close();
		}
	
		return current;	
	}

	/**
	 * Does a complete process (extraction + washing) on the given stream
	 * @param is The stream to be processed, will be closed at the end of processing.
	 * @return JDOM XML-Document 
	 */
	protected Document process(InputStream is) throws Exception
	{
		Document current;
		try 
		{
			current = extractor.getDocument(is);
			if (elements != null)
				for(PipelineElement pe : elements)
				{	
					current = pe.process(current);
				}
		}
		finally
		{
			checkPDFont();
			is.close();
		}
		return current;	
	}

	
	//have some object reuse:
	private org.jdom.output.XMLOutputter xmlout = new org.jdom.output.XMLOutputter(Format.getPrettyFormat());
	
	
	/**
	 * Controls whether long running extraction jobs are aborted (giving no result) after the LONG_JOB_TIME
	 * has timed out. Defaults to false.
	 */
	public static boolean ABORT_LONG_JOBS = false;
	/**
	 * A job must run longer than this to be a long job. Given in seconds. Defaults to 60.
	 */
	public static int LONG_JOB_TIME = 60;
	
	
	/**
	 * Get the XML-representation of extract and postprocessed document from URL. Extraction will
	 * be done in a newly created worker thread.
	 * @param url Url to the PDF.
	 * @return String representation of the XML generated by the Extractor.
	 * @throws Exception if anything went wrong.
	 */
	public String getXMLRepresentation(String url) throws Exception
	{
		URL u = new URL(url);

		InputStream is = new BufferedInputStream(u.openStream());
		Document d = null;
		
		ExecutorService es = Executors.newSingleThreadExecutor();	
		ExtractionJob ej = new ExtractionJob(this, is);
		
		//Execute the job, then immediately shut the pool down.
		es.execute(ej);
		es.shutdown();
		
		//Wait until we are done.
		for(;;)
		{
			try
			{
				es.awaitTermination(LONG_JOB_TIME, TimeUnit.SECONDS);
				//If we are aborting, shut down the worker now and return nothing.
				if(ABORT_LONG_JOBS)
				{
					es.shutdownNow();
					return null;
				}
				//If we are done, quit the loop
				if(es.isTerminated());
						break;
				
			}
			catch(InterruptedException ie)
			{
				//FIXME, currently just go on about the business, maybe we should quit here.
			}
		}
		
		//We can now get the result.
		d = ej.d;
	
	
		if(d == null)
			return null;
		return xmlout.outputString(d);
	}
	
	/**
	 * Extract a pdf-file. Will not use workers.
	 * @param f The PDF-file to be extracted.
	 * @return XMLRepresentation as string.
	 * @throws Exception if anything goes wrong.
	 */
	public String getXMLRepresentationNoWorkers(File f) throws Exception
	{
		Document d = process(f);
		return xmlout.outputString(d);
	}
	
	private class ExtractionJob implements Runnable
	{
		Pipeline parent;
		InputStream is;
		Document d;
		
		
		
		public ExtractionJob(Pipeline parent, InputStream is)
		{
			super();
			this.parent = parent;
			this.is = is;
			
		}
		public void run()
		{
			try
			{
				d = process(is);
			}
			catch (InterruptedException ie)
			{
				System.err.println("Aborting extraction");
			}
			catch (Exception e)
			{
				// TODO Auto-generated catch block
				e.printStackTrace(System.err);
			}
			
		}
	}

}
